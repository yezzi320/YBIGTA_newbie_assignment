# PROMPTING.md

## 1. 정답률 비교 (0-shot / 3-shot / 5-shot)

| 방식           | 0-shot | 3-shot | 5-shot |
|----------------|--------|--------|--------|
| Direct         | 18.00% | 20.00% | 20.00% |
| CoT            | 64.00% | 52.00% | 62.00% |
| My Prompting   | 78.00% | 78.00% | 72.00% |


---

## 2. CoT가 Direct보다 나은 이유

**Direct Prompting**은 문제를 보고 정답만 출력하게 유도한다. 단순하거나 계산이 적은 문제에서는 잘 작동하지만, 복잡한 문제에서는 중간 추론이 생략되어 오류 가능성이 높아진다.

**Chain-of-Thought Prompting (CoT)**은 다음과 같은 이유로 더 효과적이다.

- 문제 해결을 여러 단계로 나누어 설명한다.
- 중간 계산 단계를 통해 논리적 오류를 줄인다.
- 모델의 reasoning 능력을 활용한다. 

즉, CoT는 **복잡한 문제일수록 정답률이 높아지는 경향**을 보인다. 

---

## 3. My_prompting이 CoT보다 나은 이유


- **명확한 지침 제공**: “Answer: <숫자>” 형식으로 명시하여 정답 추출이 용이함
- **불필요한 출력 제거**: “Sure!”, “Let's solve!” 등 의미 없는 문장을 차단
- **추론 분리**: reasoning과 final answer를 명확히 분리하여 혼동을 줄임
- **모델 응답 일관성 향상**: 포맷 강제화를 통해 응답의 구조화 가능

My_prompting 기법은 0-shot, 3-shot, 5-shot 모두에서 **Direct Prompting 및 CoT Prompting보다 높은 정확도**를 기록했다. 명확한 출력 포맷과 단계적 사고를 조합한 방식이 모델 성능을 향상시켰다고 생각한다. 

